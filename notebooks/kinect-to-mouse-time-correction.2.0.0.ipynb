{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to get the delay between the kinect stream and the other streams in the .xdf file. \n",
    "\n",
    "# The problem\n",
    "\n",
    "Due to a bug in LSL_Kinect, the timestamps in the kinect streams are relative to the computer's startup time, whereas timestamps should be defined by LSL to enable synchronization with other streams.  \n",
    "As a consequence, the kinect streams are delayed compared to the other streams, and the value of the delay is unknown (but constant).\n",
    "\n",
    "# The solution\n",
    "Hopefully, the kinect streams are also saved in .csv files, and the mouse streams are saved in other .csv files.\n",
    "\n",
    "The solution is to use the .csv files corresponding to the .xdf file so to  :\n",
    "- get the kinect-to-csv delay : the delay between the kinect stream and the corresponding csv file\n",
    "- get the mouse-to-csv delay : the delay between mouse stream and the corresponding csv file  \n",
    "- compute the kinect-to-mouse delay : the delay between the kinect stream and the mouse stream\n",
    "\n",
    "Then, we can :\n",
    "- compute the corrected kinect timestamps : the timestamps of the kinect stream shifted by the kinect-to-mouse delay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be the set to false for production use\n",
    "# and set to true for testing (default) but can be already set to false from outside (e.g., by the test script)\n",
    "\n",
    "if \"doRunTests\" not in globals():\n",
    "    doRunTests = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Load the .xdf file\n",
    "2. Load the kinect .csv file\n",
    "3. Load the mouse .csv file\n",
    "4. Compute the kinect-to-csv delay\n",
    "5. Compute the mouse-to-csv delay\n",
    "6. Compute the kinect-to-mouse delay\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of the needed csv files for the Reaching and Circle task\n",
    "\n",
    "We get the .csv files corresponding to the .xdf file from `goodFiles.log` in the visit directory.\n",
    "\n",
    "Only the Reaching and Circle tasks contain an xdf file with a kinect stream.\n",
    "\n",
    "NOTE : for the mouse, we shall not use the data csv files, but only the marker csv files. For the kinect, we shall use the data and marker csv files (again a bug in LSL_Kinect).\n",
    "\n",
    "The csv files that are expected are: \n",
    "\n",
    "- the kinect csv files (if they exist) \n",
    "    - `*_k.csv`: kinect data file \n",
    "    - `*_k_m.csv`: the kinect marker file\n",
    "\n",
    "- the mouse csv marker files for the Reaching task (if they exist) \n",
    "    - `*_r_l_m_mau_np.csv`: mouse marker file for maximal arm use with the non-paretic arm\n",
    "    - `*_r_l_m_mau_p.csv`: mouse marker file for maximal arm use with the paretic arm\n",
    "    - `*_r_l_m_sau_np.csv`: mouse marker file for spontaneous arm use with the non-paretic arm\n",
    "    - `*_r_l_m_sau_p.csv`: mouse marker file for spontaneous arm use with the paretic arm\n",
    "\n",
    "- the mouse csv marker files for the Circle task (if they exist) \n",
    "    - `*_c_l_m_np.csv`: mouse marker file for the non-paretic arm\n",
    "    - `*_c_l_m_p.csv`: mouse marker file for the paretic arm\n",
    "\n",
    "\n",
    "The minimal set of files that are mandatory **for each task** are:\n",
    "- the xdf file (the file that contains the kinect stream with wrong timestamps + the mouse stream with correct timestamps) \n",
    "- the kinect data csv file (the file that contains the kinect stream with correct timestamps)\n",
    "- the kinect marker csv file (the file that contains the kinect marker stream with correct timestamps)\n",
    "- one mouse marker csv file (the file that contains the mouse stream with correct timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need the expected file list as created by the checkFilesInVisit notebook\n",
    "\n",
    "# save current doRunTests value\n",
    "doRunTestsOld = doRunTests\n",
    "\n",
    "# run the outside notebooks (to get the functions)\n",
    "doRunTests = False  # we need this to avoid running the tests in the outside notebooks\n",
    "%run -i \"checkFilesInVisit.ipynb\"  # we need this to get the functions\n",
    "\n",
    "# restore the doRunTests value\n",
    "doRunTests = doRunTestsOld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def load_goodFiles(visit_path):\n",
    "    \"\"\"load the goodFiles.log file\"\"\"\n",
    "\n",
    "    fullFname_goodFiles = os.path.join(visit_path, \"goodFiles.log\")\n",
    "    goodFiles = []\n",
    "    with open(fullFname_goodFiles, \"r\") as f:\n",
    "        for line in f:\n",
    "            goodFiles.append(line.strip())\n",
    "\n",
    "    return goodFiles\n",
    "\n",
    "\n",
    "def get_xdf_files(goodFiles):\n",
    "    \"\"\"get the xdf files from the goodFiles list\"\"\"\n",
    "    # should be 2 xdf files: *r.xdf and *c.xdf\n",
    "    xdf_files = []\n",
    "    for f in goodFiles:\n",
    "        if f.endswith(\".xdf\"):\n",
    "            xdf_files.append(f)\n",
    "\n",
    "    return xdf_files\n",
    "\n",
    "\n",
    "def get_csv_files_for_xdf(xdf_file, goodFiles):\n",
    "    \"\"\"get the csv files that are associated with the xdf file\"\"\"\n",
    "    csv_files = []\n",
    "    xdf_fname_no_ext = os.path.splitext(xdf_file)[0]\n",
    "    task_token = xdf_fname_no_ext.split(\"_\")[-1]\n",
    "    for f in goodFiles:\n",
    "        if f.endswith(\".csv\"):\n",
    "            if \"_\" + task_token + \"_\" in f:\n",
    "                csv_files.append(f)\n",
    "\n",
    "    return csv_files\n",
    "\n",
    "\n",
    "def get_expected_file_endings(visit_path):\n",
    "    \"\"\"get the expected file endings for the visit using the ExpectedRearmVisit class\"\"\"\n",
    "    expected_files = ExpectedRearmVisit(visit_path).expectedFiles\n",
    "    expected_files = [\n",
    "        x for x in expected_files if \"Reaching\" in x[0] or \"Circle\" in x[0]\n",
    "    ]\n",
    "\n",
    "    expected_endings = {\"Reaching\": [], \"Circle\": []}\n",
    "    for expected_task_list in expected_files:\n",
    "        if \"Reaching\" in expected_task_list[0]:\n",
    "            for fname in expected_task_list[1]:\n",
    "                if fname.endswith(\".csv\"):\n",
    "                    expected_endings[\"Reaching\"].append(fname.split(\"V?\")[-1])\n",
    "        if \"Circle\" in expected_task_list[0]:\n",
    "            for fname in expected_task_list[1]:\n",
    "                if fname.endswith(\".csv\"):\n",
    "                    expected_endings[\"Circle\"].append(fname.split(\"V?\")[-1])\n",
    "\n",
    "    return expected_endings\n",
    "\n",
    "\n",
    "def check_expected_csv_files(xdf_csv_files):\n",
    "    \"\"\"Check if the expected csv files are present for the xdf files\n",
    "    return a message with the errors found\"\"\"\n",
    "\n",
    "    expected_endings = get_expected_file_endings(visit_path)\n",
    "    msg = \"\"\n",
    "\n",
    "    for xdf_csv in xdf_csv_files:\n",
    "        xdf_fname = xdf_csv[\"xdf\"]\n",
    "        csv_files = xdf_csv[\"csv\"]\n",
    "        if xdf_fname.endswith(\"_r.xdf\"):\n",
    "            expected_ends = expected_endings[\"Reaching\"]\n",
    "        elif xdf_fname.endswith(\"_c.xdf\"):\n",
    "            expected_ends = expected_endings[\"Circle\"]\n",
    "        else:\n",
    "            msg += f\"Unexpected xdf file ending for {xdf_fname}\\n\"\n",
    "            continue\n",
    "\n",
    "        for ending in expected_ends:\n",
    "            found = False\n",
    "            for csv in csv_files:\n",
    "                if csv.endswith(ending):\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                msg += f\"Expected file ending {ending} not found for {xdf_fname}\\n\"\n",
    "\n",
    "    if xdf_csv_files is None or len(xdf_csv_files) == 0:\n",
    "        msg = \"No xdf files found\\n\"\n",
    "\n",
    "    if len(xdf_csv_files) == 1:\n",
    "        msg = f\"Only one xdf file found (expecting two xdf files) \\n\"\n",
    "\n",
    "    return msg\n",
    "\n",
    "\n",
    "def get_xdf_and_corresponding_csv_files_in_file_list(goodFiles):\n",
    "    \"\"\"Get the xdf and corresponding csv files in the goodFiles list\"\"\"\n",
    "\n",
    "    # check that gooFiles is a list of strings\n",
    "    if not all(isinstance(x, str) for x in goodFiles):\n",
    "        raise ValueError(\"goodFiles should be a list of strings\")\n",
    "    \n",
    "    xdf_files = get_xdf_files(goodFiles)\n",
    "    xdf_csv_files = []\n",
    "    for f in xdf_files:\n",
    "        csv_files = get_csv_files_for_xdf(f, goodFiles)\n",
    "        xdf_csv_files.append({\"xdf\": f, \"csv\": csv_files})\n",
    "\n",
    "    return xdf_csv_files\n",
    "\n",
    "\n",
    "def check_mandatory_files(xdf_csv_files):\n",
    "    \"\"\"Check if the mandatory files are present for the xdf file\"\"\"\n",
    "\n",
    "    import fnmatch\n",
    "\n",
    "    mandatory_patterns = {\n",
    "        \"r\": [\"*_r_k.csv\", \"*_r_k_m.csv\", \"*_r_l*.csv\"],\n",
    "        \"c\": [\"*_c_k.csv\", \"*_c_k_m.csv\", \"*_c_l*.csv\"],\n",
    "    }\n",
    "    msg = \"\"\n",
    "\n",
    "    for xdf_csv in xdf_csv_files:\n",
    "        xdf_file = xdf_csv[\"xdf\"]\n",
    "        csv_files = xdf_csv[\"csv\"]\n",
    "\n",
    "        if xdf_file.endswith(\"_r.xdf\"):\n",
    "            mandatory_fname_pattern = mandatory_patterns[\"r\"]\n",
    "        elif xdf_file.endswith(\"_c.xdf\"):\n",
    "            mandatory_fname_pattern = mandatory_patterns[\"c\"]\n",
    "        else:\n",
    "            msg += f\"Unexpected xdf file ending for {xdf_file}\\n\"\n",
    "            return msg\n",
    "\n",
    "        for pattern in mandatory_fname_pattern:\n",
    "            found = False\n",
    "            for fname in csv_files:\n",
    "                # if f.endswith(ending):\n",
    "                if fnmatch.fnmatch(fname, pattern):\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                msg += f\"Mandatory file {pattern} not found for {xdf_file}\\n\"\n",
    "\n",
    "    return msg\n",
    "\n",
    "def get_xdf_and_corresponding_csv_files_in_visit(visit_path):\n",
    "    \"\"\"Get the xdf and corresponding csv files in the visit\"\"\"\n",
    "\n",
    "    goodFiles = load_goodFiles(visit_path)\n",
    "    xdf_csv_files = get_xdf_and_corresponding_csv_files_in_file_list(goodFiles)\n",
    "    mandatory_files_error = check_mandatory_files(xdf_csv_files)\n",
    "\n",
    "    return  xdf_csv_files, mandatory_files_error\n",
    "     \n",
    "\n",
    "if doRunTests:\n",
    "    visit_path = \"../dat/ReArm.lnk/ReArm_C1P02/ReArm_C1P02_20210306_V1\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P02/ReArm_C1P02_20210419_V2\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P02/ReArm_C1P02_20210715_V3\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P07/ReArm_C1P07_20210716_V1\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P07/ReArm_C1P07_20210820_V2\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P07/ReArm_C1P07_20211116_V3\"\n",
    "\n",
    "    xdf_csv_files, mandatory_files_error = get_xdf_and_corresponding_csv_files_in_visit(visit_path)\n",
    "\n",
    "    if mandatory_files_error:\n",
    "        print(\n",
    "            \"At least one mandatory file is missing: \\n\" + mandatory_files_error\n",
    "        )\n",
    "\n",
    "    print(\"XDF and CSV files that were found as expected:\")\n",
    "    for xdf_csv in xdf_csv_files:\n",
    "        print(\"  \" + xdf_csv[\"xdf\"])\n",
    "        for csv in xdf_csv[\"csv\"]:\n",
    "            print(f\"    {csv}\")\n",
    "\n",
    "    print(\"\\nReported error msg (you will see nothing below if all is as expected):\")\n",
    "    print(check_expected_csv_files(xdf_csv_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a marker csv file\n",
    "\n",
    "We have to read a marker csv file and return a list of [timestamp, marker] pairs.   \n",
    "We want to read both kinect and mouse marker csv files, but the kinect markers lack the timestamp column.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def readMarkerCsv(fnameMarkerCsv):\n",
    "    \"\"\"Read a marker csv file and return a list of [timestamp, marker] pairs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fnameMarkerCsv : str\n",
    "        Full filename of the marker csv file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    out : list\n",
    "        List of [timestamp, marker] pairs\n",
    "            timestamp : float (in seconds)\n",
    "            marker : str\n",
    "    \"\"\"\n",
    "\n",
    "    if not fnameMarkerCsv.endswith(\".csv\"):\n",
    "        raise ValueError(\"The file must be a csv file\")\n",
    "\n",
    "    with open(fnameMarkerCsv, \"r\") as fname:\n",
    "        txt = fname.readlines()\n",
    "\n",
    "    lines = [line.split(\",\") for line in txt]\n",
    "\n",
    "    # PROBLEM: kinect markers lack the timestamp column\n",
    "    # a marker is a line with 3 tokens : datetime,timestamp,marker \\n\n",
    "    # ACTION : add the timestamp column if we have only 2 columns\n",
    "    for i in range(len(lines)):\n",
    "        if len(lines[i]) == 2 and lines[i][0][0].isdigit():\n",
    "            # create a timestamp that is in milliseconds (as in mouse markers)\n",
    "            timestamp = (\n",
    "                datetime.strptime(lines[i][0], \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "                * 1000\n",
    "            )\n",
    "            lines[i].insert(1, str(timestamp))\n",
    "            txt[i] = \",\".join(lines[i])\n",
    "\n",
    "    # PROBLEM: mouse markers lack the quotes around the multiline markers\n",
    "    # find the lines where token 3 is \"\\n\" = start of a multiline marker\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        # find the start of a multiline marker\n",
    "        if len(line) == 3 and line[2] == \"\\n\":\n",
    "            # add a \" before the end of the line\n",
    "            txt[i] = txt[i][:-1] + '\"\\n'\n",
    "            # find the end of the multiline marker\n",
    "            for j in range(i + 1, len(lines)):\n",
    "                # if we have a normal one-line-marker\n",
    "                if len(lines[j]) == 3:\n",
    "                    # add a \" before the end of the line (of the previous line)\n",
    "                    txt[j - 1] = txt[j - 1][:-1] + '\"\\n'\n",
    "                    break\n",
    "                # if are at the end of the file\n",
    "                if j == len(lines) - 1 and len(lines[j]) != 3:\n",
    "                    # add a \" before the end of the line\n",
    "                    txt[j] = txt[j][:-1] + '\"\\n'\n",
    "                    break\n",
    "\n",
    "    # write the modified file to a temporary file and load it with np.loadtxt\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fname:\n",
    "        fname.writelines(txt)\n",
    "        tempFileName = fname.name\n",
    "    lines = np.loadtxt(\n",
    "        tempFileName, skiprows=3, delimiter=\",\", quotechar='\"', dtype=str\n",
    "    )\n",
    "\n",
    "    # remove the first column (we shall need only the timestamp and the marker to compare with the xdf file)\n",
    "    lines = np.delete(lines, 0, 1)\n",
    "\n",
    "    # return a list of [timestamp, marker] pairs\n",
    "    out = []\n",
    "    for line in lines:\n",
    "        # CAUTION : the timestamp must be in seconds (as in xdf files)\n",
    "        timestamp = float(line[0]) / 1000\n",
    "        marker = line[1]\n",
    "        out.append([timestamp, marker])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    fnameMarkerCSV = \"/Users/denismottet/Documents/GitHub/Rearm-CheckFiles/dat/ReArm.lnk/ReArm_C1P02/Circle/ReArm_C1P02_20210322_1_c_l_m_np.csv\"\n",
    "    fnameMarkerCSV = \"/Users/denismottet/Documents/GitHub/Rearm-CheckFiles/dat/ReArm.lnk/ReArm_C1P02/Reaching/ReArm_C1P02_20210322_1_r_k_m.csv\"\n",
    "    fnameMarkerCSV = \"/Users/denismottet/Documents/GitHub/Rearm-CheckFiles/dat/ReArm.lnk/ReArm_C1P02/ReArm_C1P02_20210306_V1/ReArm_C1P02_20210306_V1_Circle/ReArm_C1P02_20210322_V1_c_k_m.csv\"\n",
    "    fnameMarkerCSV = \"/Users/denismottet/Documents/GitHub/Rearm-CheckFiles/dat/ReArm.lnk/ReArm_C1P07/ReArm_C1P07_20210820_V2/ReArm_C1P07_20210820_V2_Reaching/ReArm_C1P07_20210820_V2_r_k_m.csv\"\n",
    "\n",
    "    visit_path = \"../dat/ReArm.lnk/ReArm_C1P02/ReArm_C1P02_20210306_V1\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P02/ReArm_C1P02_20210419_V2\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P02/ReArm_C1P02_20210715_V3\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P07/ReArm_C1P07_20210716_V1\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P07/ReArm_C1P07_20210820_V2\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P07/ReArm_C1P07_20211116_V3\"\n",
    "\n",
    "    xdf_csv_files, mandatory_files_error = get_xdf_and_corresponding_csv_files_in_visit(visit_path)\n",
    "\n",
    "    if not mandatory_files_error:\n",
    "        # print the content of all marker csv files\n",
    "        for xdf_csv in xdf_csv_files:\n",
    "            for csv in xdf_csv[\"csv\"]:\n",
    "                if \"_k_m\" in csv or \"_l_m\" in csv:\n",
    "                    print(f\"\\n----->>>>>>  Reading {csv}\")\n",
    "                    fnameMarkerCSV = os.path.join(visit_path, csv)\n",
    "                    lines = readMarkerCsv(fnameMarkerCSV)\n",
    "                    # print the lines\n",
    "                    for line in lines:\n",
    "                        print(line)\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            \"At least one mandatory file is missing: \\n\" + mandatory_files_error\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of [timestamp, marker] pairs from all mouse csv files corresponding to one xdf file\n",
    "\n",
    "A single list of [timestamp, marker] pairs from all mouse csv files corresponding to one xdf file should correspond to the mouse marker stream in the xdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mouse_markers(xdf_csv):\n",
    "    \"\"\"Get the mouse markers from the csv files list and return them as a list of [timestamp, marker] pairs\"\"\"\n",
    "\n",
    "    mouse_markers = []\n",
    "\n",
    "    for csv in xdf_csv:\n",
    "        if \"_l_m\" in csv:\n",
    "            fnameMarkerCSV = os.path.join(visit_path, csv)\n",
    "            lines = readMarkerCsv(fnameMarkerCSV)\n",
    "            mouse_markers.extend(lines)\n",
    "\n",
    "    # sort the markers by timestamp\n",
    "    mouse_markers.sort(key=lambda x: x[0])\n",
    "\n",
    "    return mouse_markers\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "\n",
    "    visit_path = \"../dat/ReArm.lnk/ReArm_C1P02/ReArm_C1P02_20210306_V1\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P02/ReArm_C1P02_20210419_V2\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P02/ReArm_C1P02_20210715_V3\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P07/ReArm_C1P07_20210716_V1\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P07/ReArm_C1P07_20210820_V2\"\n",
    "    # visit_path = \"../dat/ReArm.lnk/ReArm_C1P07/ReArm_C1P07_20211116_V3\"\n",
    "\n",
    "    xdf_csv_files, mandatory_files_error = get_xdf_and_corresponding_csv_files_in_visit(\n",
    "        visit_path\n",
    "    )\n",
    "\n",
    "    mouse_markers_r = []\n",
    "    mouse_markers_c = []\n",
    "\n",
    "    if not mandatory_files_error:\n",
    "        for xdf_csv in xdf_csv_files:\n",
    "            if xdf_csv[\"xdf\"].endswith(\"_r.xdf\"):\n",
    "                mouse_markers_r = get_mouse_markers(xdf_csv[\"csv\"])\n",
    "            if xdf_csv[\"xdf\"].endswith(\"_c.xdf\"):\n",
    "                mouse_markers_c = get_mouse_markers(xdf_csv[\"csv\"])\n",
    "    else:\n",
    "        print(\"At least one mandatory file is missing: \\n\" + mandatory_files_error)\n",
    "\n",
    "    print(f\"\\nMouse markers reaching ({len(mouse_markers_r)} markers):\")\n",
    "    for marker in mouse_markers_r:\n",
    "        print(marker)\n",
    "\n",
    "    print(f\"\\nMouse markers circle ({len(mouse_markers_c)} markers):\")\n",
    "    for marker in mouse_markers_c:\n",
    "        print(marker)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
